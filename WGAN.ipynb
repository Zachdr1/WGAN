{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    LeakyReLU,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Activation,\n",
    "    Input,\n",
    "    Reshape,\n",
    "    Conv2DTranspose\n",
    ")\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN():\n",
    "    def __init__(self, dataset, lr=5e-5, c=0.01, m=64, n_critic=5, min_z=-1, max_z=1):\n",
    "        # Config\n",
    "        self.lr = lr\n",
    "        self.c = c\n",
    "        self.m = m\n",
    "        self.n_critic = 5\n",
    "        self.min_z = min_z\n",
    "        self.max_z = max_z\n",
    "        \n",
    "        # Models\n",
    "        self.C = self.critic()\n",
    "        self.G = self.generator()\n",
    "        \n",
    "        # Data\n",
    "        self.dataset = dataset\n",
    "        self.data_iter = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "        \n",
    "        # Optimizers\n",
    "        self.opt = tf.keras.optimizers.RMSprop(learning_rate=self.lr)\n",
    "        \n",
    "    @tf.function\n",
    "    def C_loss(self, C_real, C_fake):\n",
    "        return tf.reduce_mean(C_real) - tf.reduce_mean(C_fake)\n",
    "    \n",
    "    @tf.function\n",
    "    def G_loss(self, C_fake):\n",
    "        return -tf.reduce_mean(C_fake)\n",
    "    \n",
    "    @tf.function\n",
    "    def C_grad(self, real_inp, fake_inp):\n",
    "        with tf.GradientTape() as tape:\n",
    "            C_real = self.C(real_inp, training=True)\n",
    "            C_fake = self.C(fake_inp, training=True)\n",
    "            loss = self.C_loss(C_real, C_fake)\n",
    "        return tape.gradient(loss, self.C.trainable_variables)\n",
    "    \n",
    "    @tf.function\n",
    "    def G_grad(self, z):\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake = self.G(z, training=True)\n",
    "            C_fake = self.C(fake, training=True)\n",
    "            loss = self.G_loss(C_fake)\n",
    "        return tape.gradient(loss, self.G.trainable_variables)\n",
    "    \n",
    "    @tf.function\n",
    "    def clip_weights(self):\n",
    "        for l in self.C.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [tf.clip_by_value(weights, -self.c, self.c) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "        for l in self.G.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [tf.clip_by_value(weights, -self.c, self.c) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "    \n",
    "    @tf.function\n",
    "    def C_train_on_batch(self):\n",
    "        z = tf.random.uniform((self.m, 100,), self.min_z, self.max_z)\n",
    "        fake_inp = self.G(z, training=True)\n",
    "        real_inp = self.get_data_batch()\n",
    "        grad = self.C_grad(real_inp, fake_inp)\n",
    "        self.opt.apply_gradients(zip(grad, self.C.trainable_variables))\n",
    "    \n",
    "    @tf.function\n",
    "    def G_train_on_batch(self):\n",
    "        z = tf.random.uniform((self.m, 100,), self.min_z, self.max_z)\n",
    "        grad = self.G_grad(z)\n",
    "        self.opt.apply_gradients(zip(grad, self.G.trainable_variables))\n",
    "\n",
    "    @tf.function\n",
    "    def get_data_batch(self):\n",
    "        return self.data_iter.get_next()\n",
    "        \n",
    "    def critic(self):\n",
    "        dropout_prob = .4\n",
    "\n",
    "        inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "        # Input size = 32x32x3\n",
    "        x = Conv2D(filters=128, kernel_size=5, padding='same', strides=(2, 2), input_shape=(32, 32, 3))(inputs)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        # Output size = 16x16x128\n",
    "\n",
    "        # Input size = 16x16x128\n",
    "        x = Conv2D(filters=256, kernel_size=5, padding='same', strides=(2, 2))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        # Output size = 8x8x256\n",
    "\n",
    "        # Input size = 8x8x256\n",
    "        x = Conv2D(filters=512, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        # Output size = 4x4x512\n",
    "\n",
    "        # Input size = 4x4x512\n",
    "        x = Conv2D(filters=1024, kernel_size=5, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        # Output size = 4x4x1024\n",
    "\n",
    "        # Input size = 4x4x1024\n",
    "        x = Flatten()(x)\n",
    "        out = Dense(1)(x)\n",
    "\n",
    "        net = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "        return net\n",
    "    \n",
    "    def generator(self):\n",
    "        dropout_prob = .4\n",
    "\n",
    "        # Input size = 100\n",
    "        inputs = Input(shape=(100,))\n",
    "        x = Dense(4*4*1024, input_shape=(100,))(inputs)\n",
    "        x = Reshape(target_shape=(4, 4, 1024))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 4x4x1024\n",
    "\n",
    "        # Input size = 4x4x1024\n",
    "        x = Conv2DTranspose(filters=512, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 8x8x512\n",
    "\n",
    "        # Input size = 8x8x512\n",
    "        x = Conv2DTranspose(filters=256, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 16x16x256\n",
    "\n",
    "        # Input size = 16x16x256\n",
    "        x = Conv2DTranspose(filters=128, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 32x32x128\n",
    "\n",
    "        # Input size = 32x32x128\n",
    "        x = Conv2DTranspose(filters=3, kernel_size=5, padding='same')(x)\n",
    "        out = Activation('tanh')(x)\n",
    "        # Output size = 32x32x3\n",
    "\n",
    "        net = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "        return net\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def critic():\n",
    "        dropout_prob = .4\n",
    "\n",
    "        inputs = Input(shape=(128, 128, 3))\n",
    "\n",
    "        # Input size = 128x128x3\n",
    "        x = Conv2D(filters=128, kernel_size=5, padding='same', input_shape=(128, 128, 3))(inputs)\n",
    "        x = LeakyReLU(0.2)(x) # size = 64x64\n",
    "        # Output size = 64x64x128\n",
    "\n",
    "        # Input size = 64x64x128\n",
    "        x = Conv2D(filters=256, kernel_size=5, padding='same', strides=(2, 2))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x) # size = 32x32\n",
    "        # Output size = 32x32x256\n",
    "\n",
    "        # Input size = 32x32x256\n",
    "        x = Conv2D(filters=512, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x) # size = 16x16\n",
    "        # Output size = 16x16x512\n",
    "\n",
    "        # Input size = 16x16x512\n",
    "        x = Conv2D(filters=1024, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x) # size = 8x8\n",
    "        # Output size = 8x8x1024\n",
    "\n",
    "        # Input size = 8x8x1024\n",
    "        x = Flatten()(x)\n",
    "        out = Dense(1)(x)\n",
    "\n",
    "        net = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "        return net\n",
    "    \n",
    "    def generator():\n",
    "        dropout_prob = .4\n",
    "\n",
    "        # Input size = 100\n",
    "        inputs = Input(shape=(100,))\n",
    "        x = Dense(8*8*1024, input_shape=(100,))(inputs)\n",
    "        x = Reshape(target_shape=(8, 8, 1024))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 8x8x1024\n",
    "\n",
    "        # Input size = 8x8x1024\n",
    "        x = Conv2DTranspose(filters=512, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 16x16x512\n",
    "\n",
    "        # Input size = 16x16x512\n",
    "        x = Conv2DTranspose(filters=256, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 32x32x256\n",
    "\n",
    "        # Input size = 32x32x256\n",
    "        x = Conv2DTranspose(filters=128, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "        # Output size = 64x64x128\n",
    "\n",
    "        # Input size = 64x64x128\n",
    "        x = Conv2DTranspose(filters=3, kernel_size=5, strides=(2, 2), padding='same')(x)\n",
    "        out = Activation('tanh')(x)\n",
    "        # Output size = 128x128x3\n",
    "\n",
    "        net = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (_,_) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0721 15:48:44.151719 139633154660160 deprecation.py:323] From <ipython-input-4-52f28e52ec3f>:16: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ExperimentalMapAndBatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_fn(image):\n",
    "    x = tf.reshape(tf.cast(image, tf.float32), (32,32,3))\n",
    "#     x /= 255\n",
    "    x = 2*x/255 - 1 # convert image to [-1, 1] range\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_hue(x, 0.08)\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
    "    x = tf.image.random_brightness(x, 0.05)\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
    "    return x\n",
    "\n",
    "real_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "real_ds = real_ds.shuffle(60000)\n",
    "real_ds = real_ds.repeat()\n",
    "real_ds = real_ds.apply(tf.data.experimental.map_and_batch(\n",
    "        preprocess_fn, 64, num_parallel_batches=6, drop_remainder=True))\n",
    "real_ds = real_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "wgan = WGAN(real_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.G_train_on_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "StagingError",
     "evalue": "in converted code:\n\n    <ipython-input-2-1f770587c1a2>:63 C_train_on_batch  *\n        self.opt.apply_gradients(zip(grad, self.C.trainable_variables))\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:433 apply_gradients\n        _ = self.iterations\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:532 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:620 iterations\n        aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:770 add_weight\n        aggregation=aggregation)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py:713 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:154 make_variable\n        shape=variable_shape if variable_shape else None)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n        shape=shape)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:60 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:347 variable_capturing_scope\n        lifted_initializer_graph=lifted_initializer_graph, **kwds)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:160 __init__\n        **unused_kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1754 __init__\n        extra_handle_data=extra_handle_data)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:141 variable_handle_from_shape_and_dtype\n        container=container)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:1418 var_handle_op\n        _six.raise_from(_core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    InvalidArgumentError: /job:localhost/replica:0/task:0/device:GPU:0 unknown device. name: RMSprop/iter/\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-08cda03c63ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_train_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    357\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    358\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 359\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1542\u001b[0m         self._function_attributes)\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in converted code:\n\n    <ipython-input-2-1f770587c1a2>:63 C_train_on_batch  *\n        self.opt.apply_gradients(zip(grad, self.C.trainable_variables))\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:433 apply_gradients\n        _ = self.iterations\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:532 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:620 iterations\n        aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:770 add_weight\n        aggregation=aggregation)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py:713 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:154 make_variable\n        shape=variable_shape if variable_shape else None)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n        shape=shape)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:60 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:347 variable_capturing_scope\n        lifted_initializer_graph=lifted_initializer_graph, **kwds)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:160 __init__\n        **unused_kwargs)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1754 __init__\n        extra_handle_data=extra_handle_data)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:141 variable_handle_from_shape_and_dtype\n        container=container)\n    /home/zach/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:1418 var_handle_op\n        _six.raise_from(_core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    InvalidArgumentError: /job:localhost/replica:0/task:0/device:GPU:0 unknown device. name: RMSprop/iter/\n"
     ]
    }
   ],
   "source": [
    "wgan.C_train_on_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "0.49864697\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "noise = np.random.uniform(-1.0, 1.0, size=(1, 100,))\n",
    "fake_batch = wgan.G(noise)\n",
    "print(fake_batch.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.axis('off')\n",
    "fake_batch = (fake_batch + 1) / 2\n",
    "ax1.imshow((fake_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
